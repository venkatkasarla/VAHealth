---
title: "VaHealth Medical Centers Counts"
author: "Venkat Kasarla"
date: "11/23/2017"  
output: 
    html_document:
          keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(knitr)
```

## Presented by  Venkat Kasarla 

<br>

# Introduction
Interested to know about Veterans Administration (VA) medical centers in the mainland United Statesâ€”create a listing of counts of these centers by state, including only mainland locations. Alaska, Hawaii, and U.S.territories should be omitted. DC, while not a state, is in the mainland.

<br>

### 1-a.load the VA Health rda data

```{r missmatch, echo=TRUE}
load_rda_object <- function(fname){
  e <- new.env(parent = parent.frame())
  load(fname, e)
  return(e[[ls(e)[1]]])
}
```

<br>

```{r loadrda}
va.data <- load_rda_object('../data/N-MHSS-2015-DS0001-bndl-data-r/N-MHSS-2015-DS0001-data/N-MHSS-2015-DS0001-data-r.rda')
```

<br>

### 1-b.state abbreviations without their counts and leaning state abbreviations to valid ones


```{r stateAbbr}
st.abbr <- unique(va.data$LST) %>% as.vector()
st.abbr <- gsub(" ", "", st.abbr)
```


<br>

### 1-c.Exclude Alaska - AK, Hawai - HI, US territory state code  AS, GU, PR, VI 


```{r excludeSt}
st.abbr.filt <- st.abbr[st.abbr != "AK"]
st.abbr.filt <- st.abbr.filt[st.abbr.filt != "HI"]
st.abbr.filt <- st.abbr.filt[st.abbr.filt != "AS"]
st.abbr.filt <- st.abbr.filt[st.abbr.filt != "GU"]
st.abbr.filt <- st.abbr.filt[st.abbr.filt != "PR"]
st.abbr.filt <- st.abbr.filt[st.abbr.filt != "VI"]
va.data$LST <- gsub(" ", "", va.data$LST)
va.data.mainland <- select(va.data,LST,FACILITYTYPE) %>% filter(LST %in% st.abbr.filt ) %>% filter(grepl("Veterans Administration medical center",FACILITYTYPE))
va.data.cnt <- select(va.data.mainland,LST) %>% group_by(LST) %>% data.frame() 
#Counts of VA medical centers  by State
va.data.cnt <- va.data.cnt %>% group_by(LST) %>% summarise(total =n()) %>% data.frame() 

```


<br>

### 1-d.VA Medical Centre Counts Bar Plot


```{r VACntPlot}
ggplot(va.data.cnt, aes(x=LST, y=total,col=LST)) +  geom_bar(stat="identity") + theme(axis.text.x = element_text(angle=90, hjust=0)) + scale_linetype_discrete(name="VA Medical Centre Counts") + xlab("State") + ylab("Total Counts") + ggtitle("Counts of VA Medical Centers") + theme(plot.title = element_text(hjust = 0.5))
```

### 2-a read the statesize.csv and see the issue in LST , State abbreviation is cleaned in 1A to remove space in order to have valid state code and  merge


```{r stateSize}
state.size <- read.csv('../data/statesize.csv')
```

<br>

### 2-b.Merge the such that we can calculate the VA hospitals per thousand square miles


```{r VAperSqM}
va.merged <- merge(x=state.size, y=va.data.cnt , by.x = "Abbrev" , by.y="LST")
```

<br>

### 2-c.calculate new variable VA hospitals per thousand square miles.


```{r vaSqmCnt}
va.merged$va.per.thosand.sqmile <- 0.001
data.frame(lapply(va.merged, function(y) if(is.numeric(y)) round(y, 3) else y))
va.merged <- va.merged %>% mutate(va.per.thosand.sqmile = (total/SqMiles*1000))
```


<br>


### 2-d.ggplot state on x axis for every square thousand miles for VA


```{r VatotalSqPlot}
va.merged$logSqmile = log(va.merged$va.per.thosand.sqmile)
ggplot(va.merged, aes(x = reorder(Abbrev, -total), y = total,color=Abbrev)) +  geom_bar(stat="identity") + theme(axis.text.x = element_text(angle=90, hjust=0))
quantile(va.merged$va.per.thosand.sqmile)
ggplot(va.merged, aes(x = reorder(va.per.thosand.sqmile, -total), y = total,color=Abbrev)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle=90, hjust=0))

```


<br>


### 2-e pattern and analysis

##### NJ, VT states  would have the 2 Veteran Medical Centers per  thousand sq miles approximately. RI State have atleast one Veteran Medical Centers per  thousand sq miles. The most of States  with higher frequency except NJ,VT does not seems to have the VA medical center per thousand square miles. RI State seems to have VA medical Center with lower frequency.we have to take consideration of other variables along with frequency , square miles to study further in detail of data.


<br><br><br>
